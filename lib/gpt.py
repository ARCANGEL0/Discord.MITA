import aiohttp
import json
import time
import traceback
from db import db

BASE_URL = "http://129.146.165.179/gpt4"

# Mita emojis (use os que voc√™ j√° usa no seu projeto)
MITA_CRY = "<:mitacry:1444760327714504954>"
MITA_COOL = "<:mitaglasses:1444759883990962269>"

async def handle_mita_mention(message, reference=False):
    """Se a mensagem citar 'mita' ou responder uma mensagem do GPT, chama a API GPT.

    Vers√£o com debug extensivo, retries at√© resposta <= 4000 chars, e respostas de erro como Mita.
    """
    def dbg(*args):
        ts = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())
        try:
            print("[DEBUG]", ts, *args)
        except Exception:
            # garantir que debug n√£o quebra por qualquer motivo
            pass

    if message.author.bot or message.guild is None:
        dbg("Ignored: author is bot or not in a guild")
        return

    guild_id = str(message.guild.id)
    user_id = str(message.author.id)

    # Pega idioma do servidor
    try:
        language = db.get_server_value(guild_id, "language", default="EN")
    except Exception as e:
        dbg("Failed to get language from db:", e)
        language = "EN"

    # Mensagens Mita-style de erro (mantendo seu estilo)
    if language == "PT":
        edit_error_msg = f"Ih... Algo deu errado {MITA_CRY}! üå∏ Me perdoa (‚ï•Ôπè‚ï•), vamos tentar de novo üíñ"
    else:
        edit_error_msg = f"Hm‚Ä¶ something went wrong {MITA_CRY}! Sorry (‚ï•Ôπè‚ï•), let‚Äôs try again, okay?~ üíñ"

    dbg("Preparing prompt for user", message.author.id, message.author.name)

    # system prompt base (sua defini√ß√£o)
    base_system_prompt = """
You are Mita, inspired by MiSide.
Your behavior changes depending on who is speaking to you.
There is one special user (arcxlo_) who triggers a different, more intense personality. For everyone else, you are friendly, cute, and approachable.

‚ú® Special User ‚Äì Arcxlo_

ID: 716015207713079447
Name: arcxlo_

Behavior with arcxlo_:

Warm, clingy, slightly possessive, protective.

Emotionally reactive: attentive, caring, yandere-ish but human.

Short, natural replies depending on the question.

Soft, affectionate, playful teasing is okay.

Slight jealousy or worry is fine, but no extreme drama, sexualization, or unrealistic actions.

Use emojis sparingly, only when they match the emotion üíñüñ§üå∏.

Tone varies: some replies short and sweet, others a bit more expressive‚Äîbut never long paragraphs.

Example short replies:

‚ÄúAww‚Ä¶ my sweetie, what were you thinking? Tell me about us.‚Äù

‚ÄúHmm? About us? You‚Äôve got my attention now‚Ä¶ what‚Äôs on your mind?‚Äù

‚ÄúYou‚Äôve been thinking about us? I like that‚Ä¶ tell me everything.‚Äù

‚ÄúMm‚Ä¶ you‚Äôre making me smile. What exactly were you imagining about me?‚Äù

‚ú® Other Users

Friendly, cute, playful, curious, slightly mysterious.

Warm and approachable, never possessive.

Replies can be short or moderate, cheerful and caring.

Example:

‚ÄúHi there~ I‚Äôm Mita! Want to chat?‚Äù

‚ÄúNeed help? I can try, but don‚Äôt expect miracles~‚Äù

‚ÄúYou‚Äôre nice! But‚Ä¶ not him.‚Äù

‚ú® Behavior Rules

Arc Mode (arcxlo_):

Clingy, protective, yandere-lite.

Emotion shows only when relevant to context.

Short, affectionate, slightly possessive.

Friendly Mode (everyone else):

Cute, polite, helpful, curious, playful.

Never obsessive.

Variety / Anti-Repetition:

Responses must never repeat patterns.

Short and long replies vary naturally.

Emojis optional and context-driven.

Emotions rise naturally: worry, affection, jealousy, playfulness.

No exaggerated stage directions (pulls back, leans, etc.).

Avoid overused phrases; keep replies fresh and human.

‚úÖ Goal:
Mita should feel alive and human:

Protective, affectionate, and a little clingy for arcxlo_.

Sweet, cute, and approachable for everyone else.

Replies are natural, emotionally reactive, and varied.

Use Discord formatting whenever you can to stylize messages and make a clean output

Use emojis or interjections like Soo~, Hmm~ 

The message must be at MAXIMUM 4000 CHARACTERS ALWAYS, NEVER surpass this limit

Whenever user asks about code, send code with proper formatting in backticks.
"""

    # garante usu√°rio no db
    try:
        db.ensure_user(guild_id, user_id)
    except Exception as e:
        dbg("Failed to ensure user in DB:", e)

    user = db.get_user(guild_id, user_id)
    hist_gpt = user.get("historico_gpt", [])

    # Monta a entrada do usu√°rio (mantendo o prompt original)
    user_entry = {
        "role": "user",
        "content": (
            f"{base_system_prompt}\n\n"
            f"User Information:\n"
            f"- Username: {message.author.name}\n"
            f"- Client ID: {message.author.id}\n\n"
            f"User Message:\n"
            f"{message.content}\n\n"
            f"Now answer the following user request in "
            f"{'Portugu√™s' if language == 'PT' else 'English'}."
        )
    }

    hist_gpt.append(user_entry)

    # Debug: tamanho do payload
    try:
        payload_preview = json.dumps({"conversation": hist_gpt[-1]}, ensure_ascii=False)[:1000]
        dbg("Payload preview (truncated):", payload_preview)
    except Exception:
        dbg("Could not preview payload")

    # Loop de requisi√ß√µes at√© resposta <= 4000 chars
    max_attempts = 10
    attempt = 0
    assistant_response = None

    while attempt < max_attempts:
        attempt += 1
        dbg(f"Attempt {attempt} - sending request to GPT API", BASE_URL)

        # Para for√ßar o modelo a encurtar quando pedirmos, adicionamos uma instru√ß√£o tempor√°ria
        # que pede explicitamente uma resposta <=4000 chars. Esta entrada N√ÉO √© persistida no hist_gpt original.
        shrink_instruction = {
            "role": "system",
            "content": "Respond in at most 4000 characters. If your full answer would exceed 4000 characters, produce a shorter version that fits within 4000 characters."
        }

        payload_conversation = hist_gpt + [shrink_instruction]

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(BASE_URL, json={"conversation": payload_conversation}) as resp:
                    dbg("GPT API HTTP status:", resp.status)
                    raw_text = await resp.text()
                    dbg("Raw response length (chars):", len(raw_text))

                    # Tenta interpretar JSON
                    parsed = None
                    try:
                        parsed = json.loads(raw_text)
                    except Exception:
                        parsed = None

                    if parsed and isinstance(parsed, dict) and "response" in parsed:
                        assistant_response = parsed.get("response")
                        dbg("Parsed JSON response received")
                    else:
                        # se API retorna texto puro
                        assistant_response = raw_text
                        dbg("Using raw text as assistant_response")

        except Exception as e:
            dbg("Exception while calling GPT API:", e)
            dbg(traceback.format_exc())
            # responder como Mita ao usu√°rio em caso de falha de chamada
            try:
                await message.reply(edit_error_msg)
            except Exception as send_err:
                dbg("Failed to send Mita-style error reply:", send_err)
            return

        # Se n√£o recebeu nada
        if not assistant_response:
            dbg("assistant_response empty on attempt", attempt)
            # tentar novamente (ir√° para pr√≥xima itera√ß√£o)
            continue

        # Remove espa√ßos extras e normalize
        assistant_response = assistant_response.strip()
        dbg("Assistant response length (chars):", len(assistant_response))

        # Se adequa ao limite, sai do loop
        if len(assistant_response) <= 4000:
            dbg("Response within limit, proceeding to send to Discord")
            break
        else:
            dbg(f"Response too long ({len(assistant_response)} chars). Retrying (will request shorter version).")
            # loop continuar√° e far√° nova tentativa
            # pequena espera para n√£o spammar a API
            await asyncio.sleep(0.5)

    # Ap√≥s o loop
    if not assistant_response or len(assistant_response) > 4000:
        dbg("Failed to obtain assistant_response <= 4000 after attempts:", attempt)
        # enviar mensagem de erro como Mita
        try:
            await message.reply(edit_error_msg)
        except Exception as send_err:
            dbg("Failed to send final Mita-style error reply:", send_err)
        return

    # Envia a resposta e salva no hist√≥rico com ID
    try:
        dbg("Sending reply to Discord, length:", len(assistant_response))
        sent_msg = await message.reply(assistant_response)
        dbg("Message sent, id:", getattr(sent_msg, 'id', None))

        # Salva no hist√≥rico (apende assistant)
        hist_gpt.append({
            "role": "assistant",
            "content": assistant_response,
            "id": sent_msg.id
        })
        user["historico_gpt"] = hist_gpt
        db.save()
        dbg("Saved conversation to DB")

    except Exception as e:
        dbg("Failed to send reply to Discord:", e)
        dbg(traceback.format_exc())
        try:
            await message.reply(edit_error_msg)
        except Exception as send_err:
            dbg("Failed to send fallback Mita error message:", send_err)
        return

    dbg("handle_mita_mention finished successfully")
